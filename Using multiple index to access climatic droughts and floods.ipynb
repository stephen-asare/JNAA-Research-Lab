{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf70f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########   Importing neccessary libraries  ########\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as sp\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import cartopy as cp\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ea53b",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/spi_eq.png\">\n",
    "<img src=\"Web capture_27-10-2021_152920_www.youtube.com (1).jpeg.crdownload\">\n",
    "\n",
    "\n",
    "Where: \n",
    "\n",
    "N = current monthly/yearly rainfall, in order words, of the month/year when RAI will be generated (mm); \n",
    "\n",
    "$\\overline{N}$ = monthly/yearly average rainfall of the historical series (mm); \n",
    "    \n",
    "$\\overline{M}$ = average of the ten highest monthly/yearly precipitations of the historical series (mm); \n",
    "    \n",
    "$\\overline{X}$ = average of the ten lowest monthly/ yearly precipitations of the historical series (mm); and positive anomalies have their values above average and negative anomalies have their values below average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3cafdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Specifying the path for some data since they are not in the working directory   ###########\n",
    "\n",
    "########### Path for Gauge Station Data ############\n",
    "filename = Path('data/')\n",
    "\n",
    "######## Path for CRU data  #######\n",
    "cru_path = Path('C:/Users/Stephen Asare/Desktop/DATASETS/CRU/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3208700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#########Reading in names and locations of stations  #########\n",
    "\n",
    "dat = pd.read_fwf('GMet_location_avgSI.txt', names = ['Station', 'Longitude', 'Latitude', 'St'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb5eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################  Plot for  study Area #######\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,9))                         ###### Specifying the size of the figure\n",
    "ax = plt.axes(projection = ccrs.PlateCarree())       ###### Specifying the type of geopatial plot\n",
    "ax.add_feature(cf.COASTLINE,alpha=0.8)             \n",
    "ax.add_feature(cf.BORDERS)\n",
    "#ax.add_feature(cf.LAND)\n",
    "ax.set_extent([-3.5,1.2,11.4,4.5])                   #### setting the map boundaries\n",
    "#ax.stock_img()\n",
    "ax.add_feature(cf.STATES, alpha= 0.1)               ####  adding territorial boundaries\n",
    "\n",
    "ax.plot(dat.Longitude,                            \n",
    "        dat.Latitude, \n",
    "        'ro',                                       ##### plotting the longitudes and latitudes of the station\n",
    "        ms=7, \n",
    "        color = 'k')#,\n",
    "        #transform=ccrs.Geodetic(),label='Synoptic stations')  \n",
    "\n",
    "s_stations = np.asarray(dat.Station)\n",
    "                          \n",
    "for longitude, latitude, name in zip(dat.Longitude, dat.Latitude, s_stations):\n",
    "    if name in ['Yendi']:\n",
    "        ax.text(longitude - .05, latitude - .15, \n",
    "                name, \n",
    "                va='center',\n",
    "                ha='center', transform=ccrs.Geodetic(), fontweight='bold',fontsize = '12')\n",
    "    else:    \n",
    "        ax.text(longitude + .09, latitude + .12, \n",
    "                name, \n",
    "                va='center',\n",
    "                ha='center', transform=ccrs.Geodetic(), fontweight='bold',fontsize = '12')\n",
    "\n",
    "\n",
    "ax.set_xticks([-3.2,-2.2,-1.2,0,1.2], crs=ccrs.PlateCarree())\n",
    "ax.set_yticks([11,10,9,8,7,6,5], crs=ccrs.PlateCarree())\n",
    "lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "lat_formatter = LatitudeFormatter()\n",
    "ax.xaxis.set_major_formatter(lon_formatter)\n",
    "ax.yaxis.set_major_formatter(lat_formatter)\n",
    "#plt.savefig('Synoptic Stations.pdf',bbox_inches = 'tight')\n",
    "plt.savefig('Ghana_map.JPEG',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4a044c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##############  Reading in Gridded datasets  ###########\n",
    "\n",
    "#####  CHIRPS\n",
    "\n",
    "da_data = xr.open_mfdataset('chirps/chirps-v2.0.*.days_p25.nc', combine = 'by_coords')\n",
    "ds_data = da_data.sel(time = slice('1983','2017')).precip\n",
    "gh_data = ds_data.sel(latitude = slice(4,12), longitude = slice(-3,1.5))\n",
    "gh_data = gh_data.resample(time = 'y').sum('time')\n",
    "\n",
    "\n",
    "######   CRU\n",
    "cru = xr.open_dataset(cru_path/('cru_ts4.05.1901.2020.pre.dat.nc')).pre\n",
    "cru_data = cru.sel(lat = slice(4,12), lon = slice(-3,1.5), time = slice('1983','2017'))\n",
    "cru_data = cru_data.resample(time = 'y').sum('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f575ea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c97ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Rainfall Aanomaly Index function for Station data\n",
    "\n",
    "def RAI(x):\n",
    "    anomaly = x - np.nanmean(x)\n",
    "    N_bar = x.mean()\n",
    "    X_bar = x.sort_values().head(10).mean()\n",
    "    M_bar = x.sort_values(ascending=False).head(10).mean()\n",
    "    positive = anomaly.loc[anomaly>=0]\n",
    "    negative = anomaly.loc[anomaly<0]\n",
    "    p=3*((positive)/(M_bar-N_bar))\n",
    "    n=-3*((negative)/(X_bar-N_bar))        \n",
    "    c = pd.concat([p,n]).sort_index()\n",
    "    return c\n",
    "\n",
    "\n",
    "######Rainfall Anomaly Index Function for Gridded data\n",
    "\n",
    "def RAIG(data, dimension):\n",
    "    overall_mean = data.mean(dimension)    \n",
    "    anomaly = data - overall_mean    \n",
    "    sortings = data.reduce(np.sort,dim=dimension)  \n",
    "    da_lowest_10 = sortings[:10].mean(dimension)    \n",
    "    da_highest_10 = sortings[:-10:-1].mean(dimension)\n",
    "    negatives = -3*( (anomaly.where(anomaly<0)) / (da_lowest_10-overall_mean) ) \n",
    "    positives = 3*( (anomaly.where(anomaly>0)) / (da_highest_10-overall_mean) ) \n",
    "    RAI = anomaly.where(anomaly>=0, negatives).where(anomaly<0, positives)   \n",
    "    return RAI\n",
    "\n",
    "\n",
    "#######Statistics for Rainfall events\n",
    "\n",
    "class stats:\n",
    "    def hits(gauge, gridded, case):\n",
    "        if case == 'drought':\n",
    "            output = gauge.where((gauge<=-1) & (gridded<=-1)).count()\n",
    "        elif case == 'flood':\n",
    "            output = gauge.where((gauge>=1) & (gridded>=1)).count()\n",
    "        return output\n",
    "        \n",
    "        \n",
    "    def misses(gauge, gridded, case):\n",
    "        if case == 'drought':\n",
    "            output = gauge.where((gauge<=-1) & (gridded>-1)).count()    \n",
    "                        ##### why isn't the code (Gauge.where(gauge<=-1))&(Gridded.where(dridded>=-1)    \n",
    "        elif case == 'flood':\n",
    "            output = gauge.where((gauge>=1) & (gridded<1)).count()\n",
    "        return output\n",
    "        \n",
    "    def false_alarms(gauge, gridded, case):\n",
    "        if case == 'drought':\n",
    "            output = gauge.where((gauge>-1) & (gridded<=-1)).count()\n",
    "        elif case == 'flood':\n",
    "            output = gauge.where((gauge<1) & (gridded>=1)).count()\n",
    "        return output\n",
    "      \n",
    "        \n",
    "    def correct_negatives(gauge, gridded, case):\n",
    "        if case == 'drought':\n",
    "            output = gauge.where((gauge>-1) & (gridded>-1)).count()\n",
    "        elif case == 'flood':\n",
    "            output = gauge.where((gauge<1) & (gridded<1)).count()\n",
    "        return output\n",
    " \n",
    "    \n",
    "    def POD(gauge, gridded, case):\n",
    "        H = stats.hits(gauge, gridded, case)\n",
    "        M = stats.misses(gauge, gridded, case)\n",
    "        return H/(H+M)\n",
    "\n",
    "\n",
    "    def FAR(gauge, gridded, case):\n",
    "        F = stats.false_alarms(gauge, gridded, case)\n",
    "        H = stats.hits(gauge, gridded, case)\n",
    "        return F/(H+F)\n",
    "\n",
    "    \n",
    "        \n",
    "    def nse(gauge, gridded):\n",
    "        num = ((gridded-gauge)**2).sum()\n",
    "        den = ((gauge-np.nanmean(gauge))**2).sum()\n",
    "        return 1 - (num/den)\n",
    "    \n",
    "    \n",
    "    def correlation(gauge, gridded):\n",
    "        return sp.pearsonr(gauge, gridded)[0]\n",
    "        \n",
    "  \n",
    "    def sedi(gauge, gridded, case):\n",
    "        F = stats.false_alarms(gauge, gridded, case)\n",
    "        H = stats.hits(gauge, gridded, case)\n",
    "        num = np.log10(F) - np.log10(H) - np.log10(1-F) + np.log10(1-H)\n",
    "        den = np.log10(F) + np.log10(H) + np.log10(1-F) + np.log10(1-H)\n",
    "        return num/den\n",
    "\n",
    "    def PC(gauge, gridded):\n",
    "       \n",
    "        return ((gridded - gauge) / gauge)\n",
    "    \n",
    "    \n",
    "    def standard_error(x):\n",
    "        ##### standard error function\n",
    "        try:\n",
    "            out = np.nanstd(x)/np.sqrt(np.size(x))\n",
    "        except:\n",
    "            out = x.nanstd()/np.sqrt(x.size())\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def mse(y):\n",
    "        return stats.standard_error(y)**2\n",
    "\n",
    "    \n",
    "#Chances that the event will actually occur?\n",
    "    def chance_occur(gauge, gridded, case):\n",
    "        H = stats.hits(gauge, gridded, case)\n",
    "        F = stats.false_alarms(gauge, gridded, case)\n",
    "        return (H/(H+F))*100 \n",
    "\n",
    "\n",
    "# When events occur, how often are the gridded (forecast) correct?\n",
    "    def Often_correct(gauge, gridded, case):\n",
    "        return stats.POD(gauge, gridded, case)*100\n",
    "    \n",
    "        \n",
    "#Do the forecasts (gridded) predict events too often / not too often enough?\n",
    "    def prediction(gauge, gridded, case):\n",
    "        F = stats.false_alarms(gauge, gridded, case)\n",
    "        H = stats.hits(gauge, gridded, case)\n",
    "        M = stats.misses(gauge, gridded, case)\n",
    "        return (((H+F)-(H+M))/(H+M))*100\n",
    "    \n",
    "def functions(a, b, c):\n",
    "    POD = np.round(stats.POD(a, b, c),2)\n",
    "    FAR = np.round(stats.FAR(a, b, c),2)\n",
    "    nse = np.round(stats.nse(a, b), 2)\n",
    "    sedi = np.round(stats.sedi(a, b, c), 2)\n",
    "    r = np.round(stats.correlation(a, b), 2)\n",
    "    C_H = np.round(stats.chance_occur(a, b, c), 2)\n",
    "    O_F = np.round(stats.Often_correct(a, b, c), 2)\n",
    "    pre = np.round(stats.prediction(a, b, c), 2)\n",
    "    PC = np.round(stats.PC(a,b), 2)\n",
    "    std = np.round(stats.standard_error(RAI_data.Gridded),2)\n",
    "    mse = np.round(stats.mse(RAI_data.Gridded),2)\n",
    "                   \n",
    "    return [POD, FAR, nse, r, std, mse, C_H, O_F, pre, sedi]   \n",
    "\n",
    "\n",
    "###########################\n",
    "New_data_drought = {}\n",
    "New_data_flood = {}\n",
    "for i in range (22):\n",
    "    st = dat.iloc[i,0]\n",
    "    G_met =  pd.read_fwf(filename/(st+'_1983_2017_dRR_gapless.txt'), names = ['Year', 'Month', 'Day', 'Precip'], index_col = 'Year')\n",
    "    G_met = G_met['Precip'].groupby('Year').sum()\n",
    "    RAI_Gmet = RAI(G_met)\n",
    "    \n",
    "    lon = dat.iloc[i,1]\n",
    "    lat = dat.iloc[i,2]\n",
    "    \n",
    "    st_Gridded = gh_data.sel(latitude = lat, longitude = lon, method = 'nearest')\n",
    "    RAI_Grid = RAIG(st_Gridded, 'time')\n",
    "    \n",
    "    RAI_data= pd.DataFrame(RAI_Gmet.values, columns=['Gmet'])\n",
    "    RAI_data['Gridded'] = RAI_Grid.values\n",
    "    RAI_data = RAI_data.set_index(RAI_Gmet.index)\n",
    "    \n",
    "    x = functions(RAI_data.Gmet, RAI_data.Gridded,'drought')\n",
    "    x.insert(0,lat)\n",
    "    x.insert(0,lon)\n",
    "    New_data_drought[st] = x\n",
    "    \n",
    "    z = functions(RAI_data.Gmet, RAI_data.Gridded,'flood')\n",
    "    z.insert(0,lat)\n",
    "    z.insert(0,lon)\n",
    "    New_data_flood[st] = z\n",
    "    #print(st,lon,lat,x)\n",
    "#pd.DataFrame(New_data)\n",
    "fl = pd.DataFrame(New_data_drought).T\n",
    "fl.columns = ['Lon','Lat','POD','FAR','nse', 'r','Standard_error','MSE','Chances_occur','Often_correct','Prediction','SEDI']\n",
    "\n",
    "dr = pd.DataFrame(New_data_flood).T\n",
    "dr.columns = ['Lon','Lat','POD','FAR','nse', 'r','Standard_error','MSE','Chances_occur','Often_correct','Prediction','SEDI']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2eded2",
   "metadata": {},
   "source": [
    "1. (H/(H+F))*100    #Chances that the event will actually occur?\n",
    "2. (H/(H+M))*100    # When events occur, how often are the gridded (forecast) correct?\n",
    "\n",
    "3. Do the forecasts (gridded) predict events too often / not too often enough?\n",
    "(((H+F)-(H+M))  /(H+M))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98efb88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb94d03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b36e0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######## Plots for Statistics  ######\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 3, ncols = 3, figsize = (16,20), subplot_kw = {'projection' : ccrs.PlateCarree()})\n",
    "# ax=axes.flatten()\n",
    "for i in range(9):\n",
    "    ax[i].add_feature(cf.COASTLINE.with_scale('10m'), linewidth=0.5)\n",
    "    ax[i].add_feature(cf.BORDERS,linewidth=0.5)\n",
    "    ax[i].set_extent([-3.4,1.4,11.5,4.5])\n",
    "    ax[i].set_xticks([-3.2,-2.2,-1.2,0,1.2], crs=ccrs.PlateCarree())\n",
    "    ax[i].set_yticks([11,10,9,8,7,6,5], crs=ccrs.PlateCarree())\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax[i].xaxis.set_major_formatter(lon_formatter)\n",
    "    ax[i].yaxis.set_major_formatter(lat_formatter)\n",
    "    ax[i].set_title(fl.columns[2+i])\n",
    "    \n",
    "    cb = ax[i].scatter(x=fl['Lon'], y=fl['Lat'], c=fl.iloc[:,2+i], cmap='plasma',linewidths = 5,s=100)\n",
    "    if i in [0,3,6]:\n",
    "        fig.colorbar(cb, ax=axes[int(i/3),2])\n",
    "#         plt.scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ebcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 3, ncols = 3, figsize = (16,20), subplot_kw = {'projection' : ccrs.PlateCarree()})\n",
    "ax=axes.flatten()\n",
    "for i in range(9):\n",
    "    ax[i].add_feature(cf.COASTLINE.with_scale('10m'), linewidth=0.5)\n",
    "    ax[i].add_feature(cf.BORDERS,linewidth=0.5)\n",
    "    ax[i].set_extent([-3.4,1.4,11.5,4.5])\n",
    "    ax[i].set_xticks([-3.2,-2.2,-1.2,0,1.2], crs=ccrs.PlateCarree())\n",
    "    ax[i].set_yticks([11,10,9,8,7,6,5], crs=ccrs.PlateCarree())\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax[i].xaxis.set_major_formatter(lon_formatter)\n",
    "    ax[i].yaxis.set_major_formatter(lat_formatter)\n",
    "    ax[i].set_title(dr.columns[2+i])\n",
    "    \n",
    "    cb=ax[i].scatter(x=dr['Lon'], y=dr['Lat'], c=dr.iloc[:,2+i], cmap='plasma',linewidths = 5,s=100)\n",
    "    if i in [0,3,6]:\n",
    "        fig.colorbar(cb, ax=axes[int(i/3),2])\n",
    "        plt.scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157cae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########  Script for Rinfall parttern     #########\n",
    "\n",
    "\n",
    "DATA = pd.DataFrame()\n",
    "\n",
    "for i in range (22):\n",
    "    \n",
    "    st = dat.iloc[i,0]\n",
    "    G_met =  pd.read_fwf(filename/(st+'_1983_2017_dRR_gapless.txt'), \n",
    "                         names = ['Year', 'Month', 'Day', 'Precip'], \n",
    "                         index_col = 'Year')\n",
    "\n",
    "    \n",
    "    Gauge = G_met.groupby('Year').sum('Precip').Precip  \n",
    "    \n",
    "    long = dat.iloc[i,1]\n",
    "    lati = dat.iloc[i,2]\n",
    "    chirps_gh = gh_data.sel(longitude = long, latitude = lati, method = 'nearest')\n",
    "    cru_gh = cru_data.sel(lon = long, lat = lati, method = 'nearest')\n",
    "    \n",
    "    #convert chirps and cru to dataframe\n",
    "    conv_chirps_gh = chirps_gh.to_dataframe()\n",
    "    conv_cru_gh = cru_gh.to_dataframe()\n",
    "\n",
    "    #select precip from chirps\n",
    "    precip_chirps = conv_chirps_gh['precip']\n",
    "    \n",
    "    precip_gauge = pd.DataFrame(Gauge).set_index(precip_chirps.index)\n",
    "    \n",
    "    conv_cru_gh['Stations'] = st\n",
    "    conv_cru_gh['Chirps_precip'] = precip_chirps\n",
    "    conv_cru_gh['Gauge_precip'] = precip_gauge\n",
    "    conv_cru_gh.rename(columns={'pre':'CRU_precip'}, inplace=True)\n",
    "    conv_cru_gh = pd.DataFrame(conv_cru_gh)\n",
    "\n",
    "    \n",
    "    DATA = DATA.append(conv_cru_gh, ignore_index=True)\n",
    "\n",
    "    \n",
    "DATA = DATA.set_index('Stations')\n",
    "DATA = pd.DataFrame(DATA)\n",
    "DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da48151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Plot for Rainfall pattern  #######\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (16,20), subplot_kw = {'projection' : ccrs.PlateCarree()})\n",
    "ax=axes.flatten()\n",
    "for i in range(3):\n",
    "\n",
    "    ax[i].add_feature(cf.COASTLINE.with_scale('10m'), linewidth=0.5)\n",
    "    ax[i].add_feature(cf.BORDERS,linewidth=0.5)\n",
    "    ax[i].set_extent([-3.4,1.4,11.5,4.5])\n",
    "    ax[i].set_xticks([-3.2,-2.2,-1.2,0,1.2], crs=ccrs.PlateCarree())\n",
    "    ax[i].set_yticks([11,10,9,8,7,6,5], crs=ccrs.PlateCarree())\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax[i].xaxis.set_major_formatter(lon_formatter)\n",
    "    ax[i].yaxis.set_major_formatter(lat_formatter)\n",
    "    ax[i].set_title(DATA.columns[2+i])\n",
    "\n",
    "    \n",
    "    cb = ax[i].scatter(x=DATA['lon'], y=DATA['lat'], c = DATA.iloc[:,2+i], cmap='plasma',linewidths = 5,s=100)\n",
    "\n",
    "    color_bar = fig.add_axes([0.95, 0.35, 0.025, 0.3])\n",
    "fig.colorbar(cb, cax=color_bar);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc90b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c6b679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a55ced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666aefd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad800b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff9174d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0058914f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749b39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c74bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf8cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723b8c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a68a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e78987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad13e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24be412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 101\n",
    "a=range(x)\n",
    "plt.plot(np.zeros(x),a, c='k')\n",
    "plt.plot(np.ones(x)*x,a, c='k')\n",
    "plt.plot(a, np.ones(x)*(x-1), c='k')\n",
    "plt.plot(a, np.zeros(x)*(x-1), c='k')\n",
    "\n",
    "plt.plot(np.ones(x)*x/2,a, 'k--')\n",
    "plt.plot(a,np.ones(x)*x/2, 'k--')\n",
    "\n",
    "\n",
    "plt.text(40, x+30, 'Gauge events', fontsize=16)\n",
    "plt.text(20, x+10, 'yes', fontsize=16)\n",
    "plt.text(80, x+10, 'no', fontsize=16)\n",
    "\n",
    "\n",
    "\n",
    "plt.text(-50, 40, 'Gridded\\nevents', fontsize=16)\n",
    "plt.text(-30, 20, 'no', fontsize=16)\n",
    "plt.text(-30, 80, 'yes', fontsize=16)\n",
    "\n",
    "plt.text(20, x-30, 'hits', fontsize=16)\n",
    "plt.text(70, x-30, 'false\\nalarms', fontsize=16)\n",
    "\n",
    "plt.text(20, 20,  'misses', fontsize=16)\n",
    "plt.text(60, 20,  'correct\\nnegatives', fontsize=16)\n",
    "\n",
    "\n",
    "\n",
    "plt.xticks([],[])\n",
    "plt.yticks([],[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e50982",
   "metadata": {},
   "source": [
    "1. (H/(H+F))*100    #Chances that the event will actually occur?\n",
    "2. (H/(H+M))*100    # When events occur, how often are the gridded (forecast) correct?\n",
    "\n",
    "3. Do the forecasts (gridded) predict events too often / not too often enough?\n",
    "(((H+F)-(H+M))  /(H+M))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b19bd",
   "metadata": {},
   "source": [
    "BIAS\n",
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4234fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "######################\n",
    "\n",
    "class stats:\n",
    "    def standard_error(x):\n",
    "        ##### standard error function\n",
    "        try:\n",
    "            out = np.nanstd(x)/np.sqrt(np.size(x))\n",
    "        except:\n",
    "            out = x.nanstd()/np.sqrt(x.size())\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def mse(y):\n",
    "        return stats.standard_error(y)**2\n",
    "         \n",
    "    \n",
    "    #def bias(x,y):\n",
    "    #    return (y.sum())/(x.sum())\n",
    "    def bias(x,y):\n",
    "        return np.nanmean(y) - x\n",
    "    \n",
    "\n",
    "    \n",
    "    ###PoD, FAR, FARate, PC (Percentage of Correctness), NSE (Nash-Sutcliffe Equation)\n",
    "    ###Hits, Miss, False Alarm, ...\n",
    "    \n",
    "    \n",
    "    def POD(a,b,c):\n",
    "        H = a.where((a>=c) & b.where(b>=c)).count()\n",
    "        M = 35 - H\n",
    "        p = H/(H+M)\n",
    "        return p\n",
    "    \n",
    "    def FAR(s,g,c):\n",
    "        F = g.where(g>s).count()\n",
    "        H = s.where((s>=c) & g.where(g>=c)).count()\n",
    "        FA = F/(H+F)\n",
    "        return FA\n",
    "    \n",
    "    def nse(x,y):\n",
    "        num = ((y-x)**2).sum()\n",
    "        den = ((x-np.nanmean(x))**2).sum()\n",
    "        N = 1 - (num/den)\n",
    "        return N\n",
    "    \n",
    "     #def PC(x,y):\n",
    "      #  cc = ((x-y)\\x)\n",
    "       # return cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760fece3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_files = glob.glob('data/*.txt')\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 11, ncols = 2, figsize = (18,20), sharex=True)\n",
    "ax = axes.flatten()\n",
    "for i, file in enumerate(all_files):\n",
    "    df = pd.read_fwf(file,names = ['Year','Month','Day','Rainfall'],usecols=['Rainfall'])\n",
    "    df['Date']=pd.date_range(start='1983-01-01', end='2017-12-31',freq='D')\n",
    "    df=df.set_index('Date').resample('y').sum()\n",
    "    ax[i].plot(df.index,df)\n",
    "    ax[i].set_title(file[5:-26]) \n",
    "    ax[i].set_ylim(0,2500)\n",
    "    \n",
    "    #fig.savefig('Yearly Rainfall patttern updated.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a4967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class d:\n",
    "    def open_file(path=\"~/Desktop/DATASETS\", data=None, fname='/precip.mon.mean.nc'):\n",
    "        file = xr.open_dataset(path+data.upper()+fname)\n",
    "        return file\n",
    "gauge = pd.read_csv('~/Desktop/DATASETS/GAUGE/GMet_location_avgSI.txt', usecols=[0,1,2,4], sep='\\s+', header=None)\n",
    "gauge.columns=['station','lon','lat','zone']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e041935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "\n",
    "data_names = ['CRU','GPCC', 'GPCP']#, 'CHIRPS']#,'TAMSAT','ERA5', 'CMORPH', 'PERSIANN', 'IMERG']\n",
    "filenames = ['cru_ts4.05.1901.2020.pre.dat.nc','GPCC.nc','precip.mon.mean.nc'/\\,'chirps_new.nc']\n",
    "\n",
    "labels = ['Cru','Gpcc','Gpcp']#,'CHIRPS']\n",
    "fig, axes = plt.subplots(ncols=2, nrows= len(data_names), figsize=(18,10))\n",
    "plt.subplots_adjust(bottom=0.15, right=0.75, wspace=0.35, hspace=0.5)\n",
    "data_files = ['data ' +y for y in data_names]\n",
    "for i, data in enumerate(data_names[:3]): #Datanames Subsetting Here\n",
    "    gauges = pd.DataFrame(pd.date_range(start='1983-01-01', end='2017-12-31', freq='Y'), columns=['Time'] ).set_index('Time')\n",
    "    dataset = d.open_file(path='~/Desktop/DATASETS/', data=data, fname='/'+filenames[i])\n",
    "   \n",
    "    if data == 'CRU':\n",
    "        dataset = dataset.pre.sel(lon=slice(-3.5,1.5), lat=slice(4,12), time=slice('1983','2017'))\n",
    "        \n",
    "    elif data == 'GPCC':\n",
    "        dataset  = dataset.precip.sel(lon=slice(-3.5,1.5), lat=slice(12,4), time=slice('1983','2017'))\n",
    "     \n",
    "    elif data == 'GPCP':\n",
    "        dataset  = dataset.precip.sel(lon=slice(-3.5,1.5), lat=slice(12,4), time=slice('1983','2017'))\n",
    "     \n",
    "\n",
    "    else:\n",
    "        dataset = dataset.precip.sel(lon=slice(-3,1.5), lat=slice(4,12), time=slice('1983','2017'))\n",
    "    dataset = dataset.groupby('time.year').sum('time').rename({'year':'time'})\n",
    "    #RAI_files[i] = drought_indices.RAI_XD(dataset, 'time')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a24c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbe930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = xr.open_dataset('~/Desktop/DATASETS/GPCP/precip.mon.mean.nc')\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5971aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90308bc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 3, ncols = 3, figsize = (16,20), subplot_kw = {'projection' : ccrs.PlateCarree()})\n",
    "ax=axes.flatten()\n",
    "for i in range(9):\n",
    "    ax[i].add_feature(cf.COASTLINE.with_scale('10m'), linewidth=0.5)\n",
    "    ax[i].add_feature(cf.BORDERS,linewidth=0.5)\n",
    "    ax[i].set_extent([-3.4,1.4,11.5,4.5])\n",
    "    ax[i].set_xticks([-3.2,-2.2,-1.2,0,1.2], crs=ccrs.PlateCarree())\n",
    "    ax[i].set_yticks([11,10,9,8,7,6,5], crs=ccrs.PlateCarree())\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax[i].xaxis.set_major_formatter(lon_formatter)\n",
    "    ax[i].yaxis.set_major_formatter(lat_formatter)\n",
    "    ax[i].set_title(file[5:-26])\n",
    "    dat['Rainfall'] = df.Rainfall\n",
    "\n",
    "    cb=ax[i].scatter(x=fl['Lon'], y=fl['Lat'], c=fl.iloc[:,2+i], cmap='plasma',linewidths = 5,s=100)\n",
    "    if i in [0,3,6]:\n",
    "        fig.colorbar(cb, ax=axes[int(i/3),2])\n",
    "        plt.scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101d9956",
   "metadata": {},
   "source": [
    "#### import numpy as np\n",
    "######################\n",
    "\n",
    "class stats:\n",
    "    def standard_error(x):\n",
    "        ##### standard error function\n",
    "        try:\n",
    "            out = np.nanstd(x)/np.sqrt(np.size(x))\n",
    "        except:\n",
    "            out = x.nanstd()/np.sqrt(x.size())\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def mse(y):\n",
    "        return stats.standard_error(y)**2\n",
    "         \n",
    "    \n",
    "    def bias(x,y):\n",
    "        return (y.sum())/(x.sum())\n",
    "    \n",
    "\n",
    "    \n",
    "    ###PoD, FAR, FARate, PC (Percentage of Correctness), NSE (Nash-Sutcliffe Equation)\n",
    "    ###Hits, Miss, False Alarm, ...\n",
    "    \n",
    "    \n",
    "    def pod(a,b,c):\n",
    "        H = a.where((a>=c) & b.where(b>=c)).count()\n",
    "        M = 35 - H\n",
    "        p = H/(H+M)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_data = xr.open_mfdataset('~/Desktop/Datasets/CRU/cru_ts4.05.1901.2020.pre.dat.nc')\n",
    "g_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf2237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
